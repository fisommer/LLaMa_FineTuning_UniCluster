2025-05-31 15:55:48 INFO: Starting full fine-tuning for Mark Twain
2025-05-31 15:55:56 INFO: LoRA trainable parameters:
2025-05-31 15:55:56 INFO: Loaded splits → train=4501, val=262, test=523
2025-05-31 16:17:47 INFO: Starting full fine-tuning for Mark Twain
2025-05-31 16:17:51 INFO: LoRA trainable parameters:
2025-05-31 16:17:51 INFO: Loaded splits → train=4501, val=262, test=523
2025-05-31 16:18:50 INFO: Step 50: {'loss': 6.0277, 'grad_norm': 1.596251130104065, 'learning_rate': 4.9e-05, 'epoch': 0.1777382803821373}
2025-05-31 16:20:01 INFO: Step 100: {'loss': 4.3467, 'grad_norm': 0.9095929861068726, 'learning_rate': 9.900000000000001e-05, 'epoch': 0.3554765607642746}
2025-05-31 16:21:02 INFO: Step 150: {'loss': 3.6167, 'grad_norm': 0.44827622175216675, 'learning_rate': 9.89392509294638e-05, 'epoch': 0.5332148411464119}
2025-05-31 16:22:02 INFO: Step 200: {'loss': 3.413, 'grad_norm': 0.6740706562995911, 'learning_rate': 9.571715161021285e-05, 'epoch': 0.7109531215285492}
2025-05-31 16:22:58 INFO: Step 250: {'loss': 3.3179, 'grad_norm': 0.566267192363739, 'learning_rate': 9.04755884758533e-05, 'epoch': 0.8886914019106865}
2025-05-31 16:23:52 INFO: Step 300: {'loss': 3.2928, 'grad_norm': 0.4450484812259674, 'learning_rate': 8.344609710355091e-05, 'epoch': 1.0639857809375695}
2025-05-31 16:24:46 INFO: Step 350: {'loss': 3.2703, 'grad_norm': 0.4786446988582611, 'learning_rate': 7.493919122753874e-05, 'epoch': 1.2417240613197067}
2025-05-31 16:25:40 INFO: Step 400: {'loss': 3.2595, 'grad_norm': 0.7194374799728394, 'learning_rate': 6.533064641541142e-05, 'epoch': 1.419462341701844}
2025-05-31 16:26:34 INFO: Step 450: {'loss': 3.2434, 'grad_norm': 0.42836081981658936, 'learning_rate': 5.504490093334493e-05, 'epoch': 1.5972006220839814}
2025-05-31 16:27:27 INFO: Step 500: {'loss': 3.2432, 'grad_norm': 0.38076308369636536, 'learning_rate': 4.453630703384942e-05, 'epoch': 1.7749389024661186}
2025-05-31 16:28:22 INFO: Step 550: {'loss': 3.2268, 'grad_norm': 0.4547126591205597, 'learning_rate': 3.426906085295369e-05, 'epoch': 1.952677182848256}
2025-05-31 16:29:15 INFO: Step 600: {'loss': 3.2139, 'grad_norm': 0.41924697160720825, 'learning_rate': 2.469669747350612e-05, 'epoch': 2.127971561875139}
2025-05-31 16:30:09 INFO: Step 650: {'loss': 3.2276, 'grad_norm': 0.43545255064964294, 'learning_rate': 1.6242056919195907e-05, 'epoch': 2.305709842257276}
2025-05-31 16:31:03 INFO: Step 700: {'loss': 3.2172, 'grad_norm': 0.47744718194007874, 'learning_rate': 9.278606041474202e-06, 'epoch': 2.4834481226394134}
2025-05-31 16:31:57 INFO: Step 750: {'loss': 3.2209, 'grad_norm': 0.4260459542274475, 'learning_rate': 4.11394136769554e-06, 'epoch': 2.6611864030215506}
2025-05-31 16:32:51 INFO: Step 800: {'loss': 3.2182, 'grad_norm': 0.40053629875183105, 'learning_rate': 9.762016391969385e-07, 'epoch': 2.838924683403688}
2025-05-31 16:33:40 INFO: Step 846: {'train_runtime': 948.8309, 'train_samples_per_second': 14.231, 'train_steps_per_second': 0.892, 'total_flos': 1.6175186163479347e+17, 'train_loss': 3.505927426313396, 'epoch': 3.0}
2025-05-31 16:33:40 INFO: Running validation evaluation...
2025-05-31 16:33:48 INFO: Step 846: {'eval_loss': 3.2175633907318115, 'eval_runtime': 8.0714, 'eval_samples_per_second': 32.46, 'eval_steps_per_second': 4.089, 'epoch': 3.0}
2025-05-31 16:33:48 INFO: Validation metrics: {'eval_loss': 3.2175633907318115, 'eval_runtime': 8.0714, 'eval_samples_per_second': 32.46, 'eval_steps_per_second': 4.089, 'epoch': 3.0}
2025-05-31 16:34:03 INFO: Step 846: {'eval_loss': 3.222188949584961, 'eval_runtime': 15.1078, 'eval_samples_per_second': 34.618, 'eval_steps_per_second': 4.369, 'epoch': 3.0}
2025-05-31 16:34:03 INFO: Test set metrics: {'eval_loss': 3.222188949584961, 'eval_runtime': 15.1078, 'eval_samples_per_second': 34.618, 'eval_steps_per_second': 4.369, 'epoch': 3.0}
2025-05-31 16:34:03 INFO: Full fine-tuning for Mark Twain complete.
